{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook demonstrates the code required to train and deploy two algorithms (linear regression and random forest)\n",
    "to an MLeap server. \n",
    "\n",
    "The dataset used for the demo was pulled together from individual cities' data found here: http://insideairbnb.com/get-the-data.html\n",
    "\n",
    "The sample code has the following sections:\n",
    "* Step 1: Load Data: Can be done from a flat file or from a S3 path\n",
    "* Step 2: Define Dependent and Independent (continuous and categorical) variables + Prep the data\n",
    "* Step 3: Train a linear regression and random forest model\n",
    "* Step 4: Convert the Spark Model -> MLeap Model\n",
    "* Step 5: Save the serialized models to file system\n",
    "* Step 6: Start MLeap Server and run sample requests against the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// imports\n",
    "import java.io.File\n",
    "import com.esotericsoftware.kryo.io.Output\n",
    "import com.truecar.mleap.serialization.ml.v1.MlJsonSerializer\n",
    "import com.truecar.mleap.runtime.transformer.Transformer\n",
    "import com.truecar.mleap.runtime.transformer\n",
    "import com.truecar.mleap.spark.MleapSparkSupport._\n",
    "import org.apache.spark.ml.feature.{StandardScaler, StringIndexer, VectorAssembler}\n",
    "import org.apache.spark.ml.regression.{RandomForestRegressor, LinearRegression}\n",
    "import org.apache.hadoop.fs.{FileSystem, Path}\n",
    "import org.apache.spark.ml.{Pipeline, PipelineStage}\n",
    "import org.apache.spark.sql.SQLContext\n",
    "import org.apache.spark.sql.types._\n",
    "import ml.bundle.fs.DirectoryBundle\n",
    "import com.truecar.mleap.runtime.util.LeapFrameUtil\n",
    "import com.truecar.mleap.runtime.{LocalLeapFrame, LeapFrame}\n",
    "\n",
    "import spray.json._\n",
    "import com.truecar.mleap.serialization.mleap.v1.MleapJsonSupport._\n",
    "import com.truecar.mleap.demo.server.MleapServer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load Data - Can be done from a flat file or from a S3 path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393376\n",
      "322588\n"
     ]
    }
   ],
   "source": [
    "// Step 1. Load our Airbnb dataset\n",
    "\n",
    "val inputFile = \"file:////tmp/airbnb.avro\"\n",
    "val outputFileRf = \"/tmp/transformer.rf.ml\"\n",
    "val outputFileLr = \"/tmp/transformer.lr.ml\"\n",
    "\n",
    "var dataset = sqlContext.read.format(\"com.databricks.spark.avro\").\n",
    "  load(inputFile)\n",
    "\n",
    "var datasetFiltered = dataset.filter(\"price >= 50 AND price <= 750 and bathrooms > 0.0\")\n",
    "println(dataset.count())\n",
    "println(datasetFiltered.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+------------------+\n",
      "|summary|             price|          bedrooms|         bathrooms| number_of_reviews|      cleaning_fee|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+\n",
      "|  count|            322588|            321588|            322588|            322588|            322588|\n",
      "|   mean|131.51291430555383|1.3352426085550455|1.1985721725544658|17.960878891961265| 37.61131846193907|\n",
      "| stddev| 90.03646837350907|0.8466586601060742|0.4825716067256724|28.064342708133683|42.611960498992474|\n",
      "|    min|              50.0|               0.0|               0.5|                 1|               0.0|\n",
      "|    max|             750.0|              10.0|               8.0|               735|             700.0|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasetFiltered.select(\"price\", \"bedrooms\", \"bathrooms\", \"number_of_reviews\", \"cleaning_fee\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "+-------------+-----+---------+---------+\n",
      "|         city|    n|avg_price|max_price|\n",
      "+-------------+-----+---------+---------+\n",
      "|        Paris|50081|    98.79|   1966.0|\n",
      "|       London|30836|    98.36|   1650.0|\n",
      "|     New York|28169|   168.10|   5000.0|\n",
      "|       Berlin|24256|    60.41|    650.0|\n",
      "|    Barcelona|21885|    73.07|   1100.0|\n",
      "|     Brooklyn|20327|   117.39|   4500.0|\n",
      "|  Los Angeles|18371|   134.00|  10000.0|\n",
      "|    Amsterdam|17844|   129.55|   1900.0|\n",
      "|San Francisco|11334|   200.02|  10000.0|\n",
      "|       Madrid|11315|    63.70|   3005.0|\n",
      "|      Toronto| 9218|   121.03|   2550.0|\n",
      "|      Chicago| 8264|   137.86|   2000.0|\n",
      "|       Austin| 7548|   212.92|   2549.0|\n",
      "|     MontréAl| 7411|    87.26|   2501.0|\n",
      "|    Vancouver| 7043|   124.57|   1513.0|\n",
      "|      Seattle| 6367|   127.04|   1000.0|\n",
      "|   Washington| 5638|   133.81|   1200.0|\n",
      "|     Portland| 4962|   104.93|    700.0|\n",
      "|     Montreal| 4913|    94.36|   1300.0|\n",
      "|    San Diego| 4762|   170.66|   1725.0|\n",
      "+-------------+-----+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Most popular cities (original dataset)\n",
    "dataset.registerTempTable(\"df\")\n",
    "\n",
    "sqlContext.sql(f\"\"\"\n",
    "    select \n",
    "        city,\n",
    "        count(*) as n,\n",
    "        cast(avg(price) as decimal(12,2)) as avg_price,\n",
    "        max(price) as max_price\n",
    "    from df\n",
    "    group by city\n",
    "    order by count(*) desc\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+---------+---------+\n",
      "|                city|  n|avg_price|max_price|\n",
      "+--------------------+---+---------+---------+\n",
      "|          Palm Beach| 68|   491.28|   1500.0|\n",
      "|              Malibu|341|   375.80|   4500.0|\n",
      "|   Pacific Palisades| 36|   326.00|    850.0|\n",
      "|       Darling Point| 65|   309.03|   2001.0|\n",
      "|         Watsonville| 84|   308.62|    782.0|\n",
      "|       Bilgola Beach| 32|   300.44|    890.0|\n",
      "|        Avalon Beach| 88|   278.93|   1000.0|\n",
      "|              Avalon| 84|   267.26|    850.0|\n",
      "|             Del Mar| 40|   266.20|    900.0|\n",
      "|       Playa Del Rey| 34|   255.76|    599.0|\n",
      "|            Tamarama|157|   255.55|   1000.0|\n",
      "|            La Jolla|124|   254.70|   2400.0|\n",
      "| Rancho Palos Verdes| 85|   253.44|   1250.0|\n",
      "|     Manhattan Beach|249|   252.19|   1000.0|\n",
      "| Sydney Olympic Park| 40|   250.55|    520.0|\n",
      "|              Mosman|239|   246.82|   3701.0|\n",
      "|            Capitola| 72|   246.50|    650.0|\n",
      "|La CañAda Flintridge| 34|   240.82|    900.0|\n",
      "|          Birchgrove| 35|   240.17|   1000.0|\n",
      "|             Newport|124|   232.50|    901.0|\n",
      "+--------------------+---+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Most expensive popular cities (original dataset)\n",
    "dataset.registerTempTable(\"df\")\n",
    "\n",
    "sqlContext.sql(f\"\"\"\n",
    "    select \n",
    "        city,\n",
    "        count(*) as n,\n",
    "        cast(avg(price) as decimal(12,2)) as avg_price,\n",
    "        max(price) as max_price\n",
    "    from df\n",
    "    group by city\n",
    "    order by avg(price) desc\n",
    "\"\"\").filter(\"n>25\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define Dependent and Independent (continuous and categorical) variables + Prep the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Step 2. Create our feature pipeline and train it on the entire dataset\n",
    "val continuousFeatures = Array(\"bathrooms\",\n",
    "  \"bedrooms\",\n",
    "  \"security_deposit\",\n",
    "  \"cleaning_fee\",\n",
    "  \"extra_people\",\n",
    "  \"number_of_reviews\",\n",
    "  \"review_scores_rating\")\n",
    "\n",
    "val categoricalFeatures = Array(\"room_type\",\n",
    "  \"host_is_superhost\",\n",
    "  \"cancellation_policy\",\n",
    "  \"instant_bookable\")\n",
    "\n",
    "val allFeatures = continuousFeatures.union(categoricalFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// Filter all null values\n",
    "val allCols = allFeatures.union(Seq(\"price\")).map(datasetFiltered.col)\n",
    "val nullFilter = allCols.map(_.isNotNull).reduce(_ && _)\n",
    "datasetFiltered = datasetFiltered.select(allCols: _*).filter(nullFilter).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished constructing the pipeline\n"
     ]
    }
   ],
   "source": [
    "val Array(trainingDataset, validationDataset) = datasetFiltered.randomSplit(Array(0.7, 0.3))\n",
    "\n",
    "val continuousFeatureAssembler = new VectorAssembler().\n",
    "    setInputCols(continuousFeatures).\n",
    "    setOutputCol(\"unscaled_continuous_features\")\n",
    "val continuousFeatureScaler = new StandardScaler().\n",
    "    setInputCol(\"unscaled_continuous_features\").\n",
    "    setOutputCol(\"scaled_continuous_features\")\n",
    "\n",
    "val categoricalFeatureIndexers = categoricalFeatures.map {\n",
    "    feature => new StringIndexer().\n",
    "      setInputCol(feature).\n",
    "      setOutputCol(s\"${feature}_index\")\n",
    "}\n",
    "\n",
    "val featureCols = categoricalFeatureIndexers.map(_.getOutputCol).union(Seq(\"scaled_continuous_features\"))\n",
    "val featureAssembler = new VectorAssembler().\n",
    "    setInputCols(featureCols).\n",
    "    setOutputCol(\"features\")\n",
    "val estimators: Array[PipelineStage] = Array(continuousFeatureAssembler, continuousFeatureScaler).\n",
    "    union(categoricalFeatureIndexers).\n",
    "    union(Seq(featureAssembler))\n",
    "val featurePipeline = new Pipeline().\n",
    "    setStages(estimators)\n",
    "val sparkFeaturePipelineModel = featurePipeline.fit(datasetFiltered)\n",
    "\n",
    "println(\"Finished constructing the pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Train a linear regression and random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete: Training Random Forest\n"
     ]
    }
   ],
   "source": [
    "// Step 3.1 Create our random forest model\n",
    "val randomForest = new RandomForestRegressor().\n",
    "    setFeaturesCol(\"features\").\n",
    "    setLabelCol(\"price\").\n",
    "    setPredictionCol(\"price_prediction\")\n",
    "\n",
    "val sparkPipelineEstimatorRf = new Pipeline().setStages(Array(sparkFeaturePipelineModel, randomForest))\n",
    "val sparkPipelineRf = sparkPipelineEstimatorRf.fit(trainingDataset)\n",
    "\n",
    "println(\"Complete: Training Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete: Training Linear Regression\n"
     ]
    }
   ],
   "source": [
    "// Step 3.2 Create our linear regression model\n",
    "val linearRegression = new LinearRegression().\n",
    "    setFeaturesCol(\"features\").\n",
    "    setLabelCol(\"price\").\n",
    "    setPredictionCol(\"price_prediction\")\n",
    "\n",
    "val sparkPipelineEstimatorLr = new Pipeline().setStages(Array(sparkFeaturePipelineModel, linearRegression))\n",
    "val sparkPipelineLr = sparkPipelineEstimatorLr.fit(trainingDataset)\n",
    "\n",
    "println(\"Complete: Training Linear Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Step 4.1 Assemble the final pipeline (random forest) by implicit conversion to MLeap models\n",
    "val mleapPipelineRf: transformer.PipelineModel = mleapPipelineModelToMleap.toMleap(sparkPipelineRf)\n",
    "val mleapRandomForest = mleapPipelineRf.\n",
    "  transformers(1).\n",
    "  asInstanceOf[transformer.RandomForestRegressionModel].\n",
    "  copy(predictionCol = \"price_prediction_mleap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Step 4.2 Assemble the final pipeline (linear regression) by implicit conversion to MLeap models\n",
    "val mleapPipelineLr: transformer.PipelineModel = mleapPipelineModelToMleap.toMleap(sparkPipelineLr)\n",
    "val mleapLinearRegression = mleapPipelineLr.\n",
    "  transformers(1).\n",
    "  asInstanceOf[transformer.LinearRegressionModel].\n",
    "  copy(predictionCol = \"price_prediction_mleap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----------------+-----------------+-----+------------------+----------------------+\n",
      "|bathrooms|bedrooms|security_deposit|number_of_reviews|price|  price_prediction|price_prediction_mleap|\n",
      "+---------+--------+----------------+-----------------+-----+------------------+----------------------+\n",
      "|      0.5|     0.0|             0.0|                7| 80.0|100.29437406383843|    100.29437406383843|\n",
      "|      0.5|     0.0|             0.0|               62| 60.0| 95.94272996244864|     95.94272996244864|\n",
      "|      0.5|     1.0|             0.0|                1| 77.0| 86.20607568969425|     86.20607568969425|\n",
      "|      0.5|     1.0|             0.0|                1| 89.0| 86.64785649626828|     86.64785649626828|\n",
      "|      0.5|     1.0|             0.0|                2| 50.0| 86.20607568969425|     86.20607568969425|\n",
      "|      0.5|     1.0|             0.0|                2| 50.0| 86.20607568969425|     86.20607568969425|\n",
      "|      0.5|     1.0|             0.0|                2| 65.0| 86.64785649626828|     86.64785649626828|\n",
      "|      0.5|     1.0|             0.0|                4| 50.0|  86.4080378138193|      86.4080378138193|\n",
      "|      0.5|     1.0|             0.0|                4| 50.0|  86.4080378138193|      86.4080378138193|\n",
      "|      0.5|     1.0|             0.0|                7| 80.0| 86.20607568969425|     86.20607568969425|\n",
      "+---------+--------+----------------+-----------------+-----+------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var scoredRf = sparkPipelineRf.transform(validationDataset)\n",
    "scoredRf = mleapRandomForest.sparkTransform(scoredRf)\n",
    "\n",
    "scoredRf.select(\"bathrooms\", \"bedrooms\", \"security_deposit\", \"number_of_reviews\", \"price\", \"price_prediction\", \"price_prediction_mleap\").\n",
    " //where(\"bedrooms>0 and bathrooms>0\").\n",
    "  limit(10).\n",
    "  show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----------------+-----------------+-----+------------------+----------------------+\n",
      "|bathrooms|bedrooms|security_deposit|number_of_reviews|price|  price_prediction|price_prediction_mleap|\n",
      "+---------+--------+----------------+-----------------+-----+------------------+----------------------+\n",
      "|      0.5|     1.0|             0.0|                1| 77.0|24.839041573149235|    24.839041573149235|\n",
      "|      0.5|     1.0|             0.0|                1| 89.0|43.575096596968976|    43.575096596968976|\n",
      "|      0.5|     1.0|             0.0|                2| 50.0|44.353716859385315|    44.353716859385315|\n",
      "|      0.5|     1.0|             0.0|                2| 50.0|44.353716859385315|    44.353716859385315|\n",
      "|      0.5|     1.0|             0.0|                2| 65.0| 50.89307486469713|     50.89307486469713|\n",
      "|      0.5|     1.0|             0.0|                4| 50.0| 47.98863651509491|     47.98863651509491|\n",
      "|      0.5|     1.0|             0.0|                4| 50.0| 47.98863651509491|     47.98863651509491|\n",
      "|      0.5|     1.0|             0.0|                7| 80.0| 45.06269712387224|     45.06269712387224|\n",
      "|      0.5|     1.0|             0.0|                9|100.0| 44.85589966447361|     44.85589966447361|\n",
      "|      0.5|     1.0|             0.0|               10| 69.0| 47.73616088120404|     47.73616088120404|\n",
      "+---------+--------+----------------+-----------------+-----+------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var scoredLr = sparkPipelineLr.transform(validationDataset)\n",
    "scoredLr = mleapLinearRegression.sparkTransform(scoredLr)\n",
    "\n",
    "scoredLr.select(\"bathrooms\", \"bedrooms\", \"security_deposit\", \"number_of_reviews\", \"price\", \"price_prediction\", \"price_prediction_mleap\").\n",
    "  where(\"bedrooms>0 and bathrooms>0\").\n",
    "  limit(10).\n",
    "  show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Save the serialized models to file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// Step 7. Save our MLeap pipeline to a directory\n",
    "val mleapFileRf = new File(outputFileRf)\n",
    "val mleapFileLr = new File(outputFileLr)\n",
    "\n",
    "// if you want to save to S3\n",
    "// val bundleWriter = S3BundleWriter(s3Path)\n",
    "val bundleWriterRf = DirectoryBundle(mleapFileRf)\n",
    "val bundleWriterLr = DirectoryBundle(mleapFileLr)\n",
    "\n",
    "mleapFileRf.mkdirs()\n",
    "mleapFileLr.mkdirs()\n",
    "\n",
    "val serializer = MlJsonSerializer\n",
    "\n",
    "serializer.serializeWithClass(mleapPipelineRf, bundleWriterRf)\n",
    "serializer.serializeWithClass(mleapPipelineLr, bundleWriterLr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Start MLeap Server and run sample requests against the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MleapServer(mleapPipelineRf, 8080).start()\n",
    "MleapServer(mleapPipelineLr, 8081).start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "// curl -v -XPOST \\                                                                                                                                         Workspace/mleap (develop) Hollins-MacBook-Pro\n",
    "// -H \"content-type: application/json\" \\\n",
    "// -d @/Users/hollinwilkins/Workspace/scratch/frame.json http://localhost:8080/transform\n",
    "\n",
    "\n",
    "// sbt \"server/run /tmp/transformer.rf.ml 8080\"\n",
    "// sbt \"server/run /tmp/transformer.lr.ml 8081\"\n",
    "// curl -v -XPOST \\                                                                                                                                                                 ~ Hollins-MacBook-Pro\n",
    "//   -H \"content-type: application/json\" \\\n",
    "//   -d @/Users/hollinwilkins/Workspace/scratch/frame.json http://localhost:8080/transform\n",
    "// curl -v -XPOST \\                                                                                                                                                                 ~ Hollins-MacBook-Pro\n",
    "//   -H \"content-type: application/json\" \\\n",
    "//   -d @/Users/hollinwilkins/Workspace/scratch/frame.json http://localhost:8081/transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/*\n",
    "{\n",
    "  \"schema\": {\n",
    "    \"fields\": [{\n",
    "      \"name\": \"bathrooms\",\n",
    "      \"dataType\": \"double\"\n",
    "    }, {\n",
    "      \"name\": \"bedrooms\",\n",
    "      \"dataType\": \"double\"\n",
    "    }, {\n",
    "      \"name\": \"security_deposit\",\n",
    "      \"dataType\": \"double\"\n",
    "    }, {\n",
    "      \"name\": \"cleaning_fee\",\n",
    "      \"dataType\": \"double\"\n",
    "    }, {\n",
    "      \"name\": \"extra_people\",\n",
    "      \"dataType\": \"double\"\n",
    "    }, {\n",
    "      \"name\": \"number_of_reviews\",\n",
    "      \"dataType\": \"double\"\n",
    "    }, {\n",
    "      \"name\": \"review_scores_rating\",\n",
    "      \"dataType\": \"double\"\n",
    "    }, {\n",
    "      \"name\": \"room_type\",\n",
    "      \"dataType\": \"string\"\n",
    "    }, {\n",
    "      \"name\": \"host_is_superhost\",\n",
    "      \"dataType\": \"string\"\n",
    "    }, {\n",
    "      \"name\": \"cancellation_policy\",\n",
    "      \"dataType\": \"string\"\n",
    "    }, {\n",
    "      \"name\": \"instant_bookable\",\n",
    "      \"dataType\": \"string\"\n",
    "    }]\n",
    "  },\n",
    "  \"rows\": [[2.0, 3.0, 50.0, 30.0, 2.0, 56.0, 90.0, \"Entire home/apt\", \"1.0\", \"strict\", \"1.0\"]]\n",
    "}\n",
    "*/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLeap Spark",
   "language": "",
   "name": "mleap-spark"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
